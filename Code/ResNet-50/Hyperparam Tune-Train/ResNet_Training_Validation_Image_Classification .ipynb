{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"KjauGY8pJMyI"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BTj37PBtJm_S"},"outputs":[],"source":["TRAINING_PATH = '/content/drive/MyDrive/1:1_Hanish_Acharla/Dataset/Final_Dataset/Train'\n","VALIDATION_PATH = '/content/drive/MyDrive/1:1_Hanish_Acharla/Dataset/Final_Dataset/Validation'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CoM-XvwiJ2aR"},"outputs":[],"source":["def create_model(base_model, num_classes):\n","    import tensorflow as tf\n","    # Grab the last layer and add a few extra layers to it\n","    x=base_model.output\n","    x=GlobalAveragePooling2D()(x)\n","    # Dense layer 1\n","    x=tf.keras.layers.Dense(100,activation='relu', kernel_initializer=tf.keras.initializers.VarianceScaling(), use_bias=True)(x)\n","    # Final layer with softmax activation\n","    preds=tf.keras.layers.Dense(num_classes,activation='softmax', kernel_initializer=tf.keras.initializers.VarianceScaling(), use_bias=False)(x)\n","    # Create the final model\n","    model=Model(inputs=base_model.input,outputs=preds)\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uABf6kVGKMpe"},"outputs":[],"source":["def get_optimizer(optimizer_name, learning_rate):\n","    # Import keras optimizers\n","    from tensorflow.keras.optimizers import Adam, Adadelta, Adagrad, Adamax, Ftrl, Nadam, RMSprop, SGD\n","    print('Selected Optimizer', optimizer_name)\n","    switcher = {\n","        'Adadelta': Adadelta(learning_rate=learning_rate),\n","        'Adagrad': Adagrad(learning_rate=learning_rate),\n","        'Adam': Adam(learning_rate=learning_rate),\n","        'Adamax': Adamax(learning_rate=learning_rate),\n","        'FTRL': Ftrl(learning_rate=learning_rate),\n","        'NAdam': Nadam(learning_rate=learning_rate),\n","        'RMSprop': RMSprop(learning_rate=learning_rate),\n","        'Gradient Descent': SGD(learning_rate=learning_rate)\n","    }\n","    # If optimizer_name is empty, Adam will be return as default optimizer\n","    return switcher.get(optimizer_name, Adam(learning_rate=learning_rate))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jM5L-0B5K7k3"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","import tensorflow as tf\n","from keras.applications.resnet import preprocess_input\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from keras.layers import Dense,GlobalAveragePooling2D\n","from keras.models import Model\n","from tensorflow.keras import regularizers\n","from tensorflow.keras.preprocessing import image_dataset_from_directory\n","from keras.callbacks import EarlyStopping\n","from tensorflow import keras"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"teLyFjCZLCaE"},"outputs":[],"source":["# Initialize hyper params\n","epochs = 10 #<-- increase for higher accuracy\n","base_learning_rate = 0.0001 #decrease for different results; use excel sheet to note down results from each change to learning rate and epochs\n","optimizer = 'Adam'\n","BATCH_SIZE = 32"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ltKPzSjrLDOX"},"outputs":[],"source":["IMG_SIZE = (224, 224)\n","# Create the data generation pipeline for training and validation\n","train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n","validation_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n","train_generator = train_datagen.flow_from_directory(TRAINING_PATH,\n","                                                target_size=IMG_SIZE,\n","                                                color_mode='rgb',\n","                                                batch_size=BATCH_SIZE,\n","                                                class_mode='categorical',\n","                                                shuffle=True,\n","                                                )\n","\n","validation_generator = validation_datagen.flow_from_directory(VALIDATION_PATH,\n","                                                target_size=IMG_SIZE,\n","                                                color_mode='rgb',\n","                                                batch_size=BATCH_SIZE,\n","                                                class_mode='categorical',\n","                                                shuffle=True,\n","                                                )\n","print(validation_generator.class_indices.keys())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xROChyfzL9RO"},"outputs":[],"source":["# Download the model, valid alpha values [0.25,0.35,0.5,0.75,1]\n","base_model = tf.keras.applications.ResNet50(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n","for layer in base_model.layers:\n","    layer.trainable=False\n","# Specify the number of classes\n","num_classes = 6\n","# Create the base model\n","model = create_model(base_model,num_classes)\n","print(len(base_model.layers))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Kn-VXdrRMQNa"},"outputs":[],"source":["model.compile(optimizer = get_optimizer(optimizer_name=optimizer,learning_rate=base_learning_rate),loss='CategoricalCrossentropy',metrics=['accuracy'])\n","# Adam optimizer\n","# loss function will be categorical cross entropy\n","# evaluation metric will be accuracy\n","early_stopping_monitor = EarlyStopping(\n","    monitor='val_loss',\n","    min_delta=0,\n","    patience=30,\n","    verbose=0,\n","    mode='auto',\n","    baseline=None,\n","    restore_best_weights=True\n",")\n","step_size_train = train_generator.n//train_generator.batch_size\n","history_fine = model.fit(train_generator,\n","                        epochs=epochs,\n","                        validation_data = validation_generator,\n","                        verbose=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dnGaiX84QcEO"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a0tA70vVQfnd"},"outputs":[],"source":["def visualization():\n","    import pandas as pd\n","    df = pd.DataFrame(history_fine.history)\n","    #loss plots\n","    plt.figure(figsize=(8,8))\n","    plt.plot(df['loss'], color='red', label = \"Training_loss\")\n","    plt.plot(df['val_loss'], color='blue')\n","    plt.legend(['Training Loss','Validation loss'],loc = 'best' )\n","    plt.title('Line plot of Training and Validation loss')\n","    plt.ylim(0,1)\n","    plt.show()\n","    #accuracy plots\n","    plt.figure(figsize=(8,8))\n","    plt.plot(df['accuracy'], color='red')\n","    plt.plot(df['val_accuracy'], color='blue')\n","    plt.legend(['Training acc','Validation acc'],loc = 'best' )\n","    plt.title('Line plot of Training and Validation Accuracies')\n","    plt.ylim(0,1)\n","    plt.show()\n","visualization()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xejh3h9HQjd6"},"outputs":[],"source":["# Import numpy for calculating best model accuracy\n","import numpy as np\n","# Populating matrics -> accuracy & loss\n","acc = history_fine.history['accuracy']\n","val_acc = history_fine.history['val_accuracy']\n","loss = history_fine.history['loss']\n","val_loss = history_fine.history['val_loss']\n","print('Training Accuracy: ', acc)\n","print('Validation Accuracy: ', val_acc)\n","print('Training Loss: ', loss)\n","print('Validation Loss: ', val_loss)\n","best_model_accuracy = history_fine.history['val_accuracy'][np.argmin(history_fine.history['val_loss'])]\n","print('best model accuracy: ', best_model_accuracy)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yvtciCVFQkuY"},"outputs":[],"source":["def seperate_labels(generator):\n","    x_validation = []\n","    y_validation = []\n","    num_seen = 0\n","    for x, labels in generator:\n","        x_validation.append(x)\n","        y_validation.append([argmax(label) for label in labels])\n","        num_seen += len(x)\n","        if num_seen == generator.n: break\n","    x_validation = np.concatenate(x_validation)\n","    y_validation = np.concatenate(y_validation)\n","    return x_validation, y_validation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y6UQP9zFRC-I"},"outputs":[],"source":["# Calculate and display the confusion matrix\n","import matplotlib.pyplot as plt\n","from numpy.core.fromnumeric import argmax\n","from sklearn.metrics import ConfusionMatrixDisplay\n","x_validation, y_validation = seperate_labels(validation_generator)\n","y_pred = model.predict(x_validation, batch_size=BATCH_SIZE)\n","predictions = np.apply_along_axis(argmax, 1, y_pred)\n","display_labels = validation_generator.class_indices.keys()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bd93oV4qRx0J"},"outputs":[],"source":["import seaborn as sns\n","from sklearn.metrics import confusion_matrix, classification_report\n","plt.figure(figsize = (10,10))\n","sns.heatmap(confusion_matrix(y_validation, predictions), annot = True, fmt = 'g', cmap = \"Blues\",xticklabels=display_labels, yticklabels=display_labels)\n","plt.title(\"Confusion Matrix\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W_CEkNZWR9cr"},"outputs":[],"source":["print(classification_report(y_validation, predictions))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X6BJGNoDU1k2"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}